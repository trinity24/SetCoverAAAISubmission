{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the LP solution for the first instance\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Get the absolute path of the src directory\n",
    "current_dir = os.getcwd()\n",
    "src_path = os.path.join(current_dir, '../src')\n",
    "sys.path.append(src_path)\n",
    "# Load the dataset from the file\n",
    "import experiments,inamdar_alg\n",
    "import importlib\n",
    "import setcover_dataset,setcover_lp\n",
    "importlib.reload(experiments)\n",
    "importlib.reload(inamdar_alg)\n",
    "\n",
    "from experiments import read_dataset\n",
    "from experiments import run_experiments\n",
    "from setcover_dataset import generate_setcover_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a63ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import importlib\n",
    "import experiments\n",
    "importlib.reload(experiments)\n",
    "\n",
    "\n",
    "\n",
    "from experiments import read_dataset, write_dataset, run_experiments\n",
    "def run_experiment_for_f(f_value):\n",
    "    \"\"\"\n",
    "    Run experiment for a specific f value\n",
    "    \"\"\"\n",
    "    print(f\"Starting experiment for f = {f_value}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Load dataset for this f value\n",
    "        dataset_path = f'../data/freq_data/final_dataset/instances/setcover_small_dataset_f_{f_value}.pkl'\n",
    "        loaded_dataset = read_dataset(dataset_path)\n",
    "        \n",
    "        # Run experiments for this f value\n",
    "        results = run_experiments(loaded_dataset, f_value)\n",
    "        path = f'../data/freq_data/final_dataset/results/results_{f_value}.pkl'\n",
    "        write_dataset(path, results)\n",
    "        end_time = time.time()\n",
    "        print(f\"Completed experiment for f = {f_value} in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        return f_value, results, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in experiment for f = {f_value}: {str(e)}\")\n",
    "        return f_value, None, False\n",
    "\n",
    "def run_parallel_experiments(f_values, max_workers=4):\n",
    "    \"\"\"\n",
    "    Run experiments for multiple f values in parallel\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    \n",
    "    print(f\"Starting parallel experiments for f values: {f_values}\")\n",
    "    print(f\"Using {max_workers} worker threads\")\n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Use ThreadPoolExecutor to run experiments in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all experiments\n",
    "        future_to_f = {executor.submit(run_experiment_for_f, f): f for f in f_values}\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_f):\n",
    "            f_value = future_to_f[future]\n",
    "            try:\n",
    "                f, results, success = future.result()\n",
    "                if success:\n",
    "                    results_dict[f] = results\n",
    "                    print(f\"✓ Successfully stored results for f = {f}\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed to get results for f = {f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Exception occurred for f = {f_value}: {str(e)}\")\n",
    "    \n",
    "    overall_end_time = time.time()\n",
    "    print(f\"\\nAll experiments completed in {overall_end_time - overall_start_time:.2f} seconds\")\n",
    "    print(f\"Successfully completed {len(results_dict)} out of {len(f_values)} experiments\")\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "# Example usage: Run experiments for multiple f values in parallel\n",
    "f_values = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "max_workers = 4  # Adjust based on your system's capabilities\n",
    "\n",
    "# Run parallel experiments\n",
    "all_results = run_parallel_experiments(f_values, max_workers=max_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_palette(\"Set2\") \n",
    "\n",
    "positions_fair = [i*2-0.4 for i in range(1, len(f_values)+1)]\n",
    "positions_inamdar = [i*2+0.4 for i in range(1, len(f_values)+1)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bp1 = plt.boxplot(fair_iter_times, positions=positions_fair, widths=0.6, patch_artist=True, boxprops=dict(facecolor='#66c2a5'), labels=f_values)\n",
    "bp2 = plt.boxplot(inamdar_times, positions=positions_inamdar, widths=0.6, patch_artist=True, boxprops=dict(facecolor='#fc8d62'))\n",
    "\n",
    "plt.xticks([i*2 for i in range(1, len(f_values)+1)], f_values)\n",
    "plt.xlabel('Frequency (f)')\n",
    "plt.ylabel('Running Time (seconds)')\n",
    "plt.title('Running Time Comparison: fair_iter vs inamdar')\n",
    "\n",
    "# Custom legend\n",
    "legend_handles = [\n",
    "    Patch(facecolor='#66c2a5', label='fair_iter'),\n",
    "    Patch(facecolor='#fc8d62', label='inamdar')\n",
    "]\n",
    "plt.legend(handles=legend_handles)\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "f_values = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Prepare data for boxplots\n",
    "fair_iter_approx = [all_results[f]['approximation_ratio_fair_iter'] if f!=3 else all_results[3][1]['approximation_ratio_fair_iter'] for f in f_values]\n",
    "inamdar_approx = [all_results[f]['approximation_ratio_inamdar'] if f!=3 else all_results[3][1]['approximation_ratio_inamdar'] for f in f_values]\n",
    "positions_fair = [i*2-0.4 for i in range(1, len(f_values)+1)]\n",
    "positions_inamdar = [i*2+0.4 for i in range(1, len(f_values)+1)]\n",
    "\n",
    "bp1 = plt.boxplot(fair_iter_approx, positions=positions_fair, widths=0.6, patch_artist=True, boxprops=dict(facecolor='#66c2a5'), labels=f_values)\n",
    "bp2 = plt.boxplot(inamdar_approx, positions=positions_inamdar, widths=0.6, patch_artist=True, boxprops=dict(facecolor='#fc8d62'))\n",
    "\n",
    "plt.xticks([i*2 for i in range(1, len(f_values)+1)], f_values)\n",
    "plt.xlabel('Frequency (f)')\n",
    "plt.ylabel('Approximation Ratio')\n",
    "plt.title('Approximation Ratio Comparison: fair_iter vs inamdar')\n",
    "\n",
    "plt.legend(handles=legend_handles)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = read_dataset('../data/freq_data/final_dataset/instances/setcover_small_dataset_f_3.pkl')\n",
    "print(max( list(loaded_dataset[0]['element_frequencies'].values()) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute worst-case and best-case (min) approximation ratios for shading\n",
    "worst_fair_iter = [max(ratios) for ratios in fair_iter_approx]\n",
    "best_fair_iter = [min(ratios) for ratios in fair_iter_approx]\n",
    "worst_inamdar = [max(ratios) for ratios in inamdar_approx]\n",
    "best_inamdar = [min(ratios) for ratios in inamdar_approx]\n",
    "mean_fair_iter = [np.mean(ratios) for ratios in fair_iter_approx]\n",
    "mean_inamdar = [np.mean(ratios) for ratios in inamdar_approx]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=f_values, y=worst_fair_iter, marker='o', label='Fair Iterated Rounding (worst case)', color='limegreen')\n",
    "sns.lineplot(x=f_values, y=worst_inamdar, marker='o', label='Inamdar Rounding (worst case)', color='red')\n",
    "sns.lineplot(x=f_values, y=mean_fair_iter, marker='o', label='Fair Iterated Rounding (mean)', color='darkgreen')\n",
    "sns.lineplot(x=f_values, y=mean_inamdar, marker='o', label='Inamdar Rounding (mean)', color='darkred')\n",
    "# Shaded region for fair_iter\n",
    "plt.fill_between(f_values, best_fair_iter, worst_fair_iter, color='limegreen', alpha=0.2)\n",
    "# Shaded region for inamdar\n",
    "plt.fill_between(f_values, best_inamdar, worst_inamdar, color='orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Frequency (f)')\n",
    "plt.ylabel('Worst-case Approximation Ratio')\n",
    "plt.title('Worst-case Approximation Ratio vs Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('../data/freq_data/final_dataset/plots/worst_case_approximation_ratios_vs_f.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2537ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# Compute average number of elements satisfying coverage requirements for each f\n",
    "mean_fair_iter_coverage = [np.mean(cov) for cov in fair_iter_coverage]\n",
    "mean_inamdar_coverage = [np.mean(cov) for cov in inamdar_coverage]\n",
    "\n",
    "# Compute min and max for shading\n",
    "min_fair_iter_coverage = [np.min(cov) for cov in fair_iter_coverage]\n",
    "max_fair_iter_coverage = [np.max(cov) for cov in fair_iter_coverage]\n",
    "min_inamdar_coverage = [np.min(cov) for cov in inamdar_coverage]\n",
    "max_inamdar_coverage = [np.max(cov) for cov in inamdar_coverage]\n",
    "\n",
    "plt.plot(f_values, mean_fair_iter_coverage, marker='o', label='Fair Iterated Rounding', color='#66c2a5')\n",
    "plt.plot(f_values, mean_inamdar_coverage, marker='o', label='Inamdar Rounding', color='#fc8d62')\n",
    "\n",
    "plt.fill_between(f_values, min_fair_iter_coverage, max_fair_iter_coverage, color='#66c2a5', alpha=0.2)\n",
    "plt.fill_between(f_values, min_inamdar_coverage, max_inamdar_coverage, color='#fc8d62', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Frequency (f)')\n",
    "plt.ylabel('Number of Elements Satisfying Coverage Requirements')\n",
    "plt.title('Coverage Satisfaction vs Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('../data/freq_data/final_dataset/plots/coverage_satisfaction_vs_f.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[3][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Compute mean objectives for each f value\n",
    "mean_fair_iter_obj = [np.mean(obj) for obj in [all_results[f]['tim'] if f != 3 else all_results[3][1]['fair_iter_objectives'] for f in f_values]]\n",
    "mean_inamdar_obj = [np.mean(obj) for obj in [all_results[f]['inamdar_objectives'] if f != 3 else all_results[3][1]['inamdar_objectives'] for f in f_values]]\n",
    "# mean_lp_obj = [np.mean(obj) for obj in [all_results[f]['lp_objectives'] if f != 3 else all_results[3][1]['lp_objectives'] for f in f_values]]\n",
    "\n",
    "# Compute min and max for shading\n",
    "min_fair_iter_obj = [np.min(obj) for obj in [all_results[f]['fair_iter_objectives'] if f != 3 else all_results[3][1]['fair_iter_objectives'] for f in f_values]]\n",
    "max_fair_iter_obj = [np.max(obj) for obj in [all_results[f]['fair_iter_objectives'] if f != 3 else all_results[3][1]['fair_iter_objectives'] for f in f_values]]\n",
    "min_inamdar_obj = [np.min(obj) for obj in [all_results[f]['inamdar_objectives'] if f != 3 else all_results[3][1]['inamdar_objectives'] for f in f_values]]\n",
    "max_inamdar_obj = [np.max(obj) for obj in [all_results[f]['inamdar_objectives'] if f != 3 else all_results[3][1]['inamdar_objectives'] for f in f_values]]\n",
    "\n",
    "plt.plot(f_values, mean_fair_iter_obj, marker='o', label='Fair Iterated Rounding', color='#66c2a5')\n",
    "plt.plot(f_values, mean_inamdar_obj, marker='o', label='Inamdar Rounding', color='#fc8d62')\n",
    "plt.plot(f_values, mean_lp_obj, marker='o', label='LP Relaxation', color='#8da0cb')\n",
    "\n",
    "plt.fill_between(f_values, min_fair_iter_obj, max_fair_iter_obj, color='#66c2a5', alpha=0.2)\n",
    "plt.fill_between(f_values, min_inamdar_obj, max_inamdar_obj, color='#fc8d62', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Max Frequency (f)')\n",
    "plt.ylabel('Mean Objective Value')\n",
    "plt.title('Mean Objective Value vs Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('../data/freq_data/final_dataset/plots/mean_objectives_vs_f.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(f_values, mean_fair_iter_time, marker='o', label='Fair Iterated Rounding', color='#66c2a5')\n",
    "plt.plot(f_values, mean_inamdar_time, marker='o', label='Inamdar Rounding', color='#fc8d62')\n",
    "\n",
    "plt.fill_between(f_values, min_fair_iter_time, max_fair_iter_time, color='#66c2a5', alpha=0.2)\n",
    "plt.fill_between(f_values, min_inamdar_time, max_inamdar_time, color='#fc8d62', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Frequency (f)')\n",
    "plt.ylabel('Running Time (seconds) for 100 instances')\n",
    "plt.title('Running Time Comparison: Fair Iterated Rounding vs Inamdar Rounding')\n",
    "plt.legend(handles=legend_handles)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Compute mean objectives for each f value\n",
    "mean_fair_iter_obj = [np.mean(obj) for obj in [all_results[f]['times_fair_iter'] if f != 3 else all_results[3][1]['times_inamdar'] for f in f_values]]\n",
    "mean_inamdar_obj = [np.mean(obj) for obj in [all_results[f]['times_inamdar'] if f != 3 else all_results[3][1]['times_inamdar'] for f in f_values]]\n",
    "# mean_lp_obj = [np.mean(obj) for obj in [all_results[f]['lp_objectives'] if f != 3 else all_results[3][1]['lp_objectives'] for f in f_values]]\n",
    "\n",
    "# Compute min and max for shading\n",
    "min_fair_iter_obj = [np.min(obj) for obj in [all_results[f]['fair_iter_objectives'] if f != 3 else all_results[3][1]['fair_iter_objectives'] for f in f_values]]\n",
    "max_fair_iter_obj = [np.max(obj) for obj in [all_results[f]['fair_iter_objectives'] if f != 3 else all_results[3][1]['fair_iter_objectives'] for f in f_values]]\n",
    "min_inamdar_obj = [np.min(obj) for obj in [all_results[f]['inamdar_objectives'] if f != 3 else all_results[3][1]['inamdar_objectives'] for f in f_values]]\n",
    "max_inamdar_obj = [np.max(obj) for obj in [all_results[f]['inamdar_objectives'] if f != 3 else all_results[3][1]['inamdar_objectives'] for f in f_values]]\n",
    "\n",
    "plt.plot(f_values, mean_fair_iter_obj, marker='o', label='Fair Iterated Rounding', color='#66c2a5')\n",
    "plt.plot(f_values, mean_inamdar_obj, marker='o', label='Inamdar Rounding', color='#fc8d62')\n",
    "# plt.plot(f_values, mean_lp_obj, marker='o', label='LP Relaxation', color='#8da0cb')\n",
    "\n",
    "plt.fill_between(f_values, min_fair_iter_obj, max_fair_iter_obj, color='#66c2a5', alpha=0.2)\n",
    "plt.fill_between(f_values, min_inamdar_obj, max_inamdar_obj, color='#fc8d62', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Max Frequency (f)')\n",
    "plt.ylabel('Mean Running Time (seconds) for 100 Instances')\n",
    "plt.title('Mean Running Time vs Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('../data/freq_data/final_dataset/plots/mean_objectives_vs_f.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633ae85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
